"""
ä¼˜åŒ–çš„Food-101 EfficientNet-B4 + CBAMè®­ç»ƒè„šæœ¬
ç›®æ ‡å‡†ç¡®ç‡: 90%+

ä¸»è¦ä¼˜åŒ–:
1. ä½¿ç”¨EfficientNet-B4ä½œä¸ºbackbone
2. æ”¹è¿›çš„CBAMæ³¨æ„åŠ›æœºåˆ¶
3. æ›´å¥½çš„æ•°æ®å¢å¼ºç­–ç•¥
4. ä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥
5. å®æ—¶è®­ç»ƒè¿›åº¦æ˜¾ç¤º
"""

import random
import torch
import torch.nn as nn
import numpy as np
import os
import cv2
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from torchvision import transforms, models
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, OneCycleLR
import time
import matplotlib.pyplot as plt
import torch.nn.functional as F
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support
import seaborn as sns
from pathlib import Path
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler

# è®¾ç½®å­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# å›ºå®šéšæœºç§å­å‡½æ•°
def seed_everything(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

seed_everything(42)

HW = 256  # ä½¿ç”¨æ›´å¤§çš„å›¾ç‰‡å°ºå¯¸

# é«˜çº§æ•°æ®å¢å¼ºç­–ç•¥
train_transform = transforms.Compose([
    transforms.Resize(320),  # å…ˆæ”¾å¤§åˆ°320
    transforms.RandomResizedCrop(HW, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.RandomErasing(p=0.1, scale=(0.02, 0.33), ratio=(0.3, 3.3)),  # éšæœºæ“¦é™¤
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize(320),
    transforms.CenterCrop(HW),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# æ ‡ç­¾å¹³æ»‘æŸå¤±
class LabelSmoothingCrossEntropy(nn.Module):
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, x, target):
        confidence = 1. - self.smoothing
        logprobs = F.log_softmax(x, dim=-1)
        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -logprobs.mean(dim=-1)
        loss = confidence * nll_loss + self.smoothing * smooth_loss
        return loss.mean()


# Food-101æ•°æ®é›†ç±»
class Food101Dataset(Dataset):
    def __init__(self, data_dir, meta_file, mode="train"):
        self.data_dir = data_dir
        self.mode = mode
        self.image_paths = []
        self.labels = []
        
        # è¯»å–ç±»åˆ«åç§°
        with open(os.path.join(data_dir, "meta", "classes.txt"), 'r') as f:
            self.class_names = [line.strip() for line in f.readlines()]
        
        # åˆ›å»ºç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„
        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        meta_path = os.path.join(data_dir, "meta", meta_file)
        with open(meta_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    # æ ¼å¼ï¼šclass_name/image_id
                    class_name = line.split('/')[0]
                    image_id = line.split('/')[1]
                    image_path = os.path.join(data_dir, "images", class_name, f"{image_id}.jpg")
                    
                    if os.path.exists(image_path):
                        self.image_paths.append(image_path)
                        self.labels.append(self.class_to_idx[class_name])
        
        self.labels = torch.LongTensor(self.labels)
        self.transform = train_transform if mode == "train" else val_transform
        
        print(f"åŠ è½½äº† {len(self.image_paths)} ä¸ªæ ·æœ¬")
        print(f"ç±»åˆ«æ•°é‡: {len(self.class_names)}")
    
    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert("RGB")
            image = self.transform(image)
            return image, self.labels[idx]
        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡å¤±è´¥: {self.image_paths[idx]}, é”™è¯¯: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„é»‘è‰²å›¾ç‰‡
            image = torch.zeros(3, HW, HW)
            return image, self.labels[idx]
    
    def __len__(self):
        return len(self.image_paths)


# æ”¹è¿›çš„CBAMæ¨¡å—
class CBAM(nn.Module):
    def __init__(self, channels, reduction=16):
        super(CBAM, self).__init__()
        # é€šé“æ³¨æ„åŠ›æœºåˆ¶
        self.channel_att = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels // reduction, channels, 1, bias=False),
            nn.Sigmoid()
        )
        # ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶
        self.spatial_att = nn.Sequential(
            nn.Conv2d(2, 1, 7, padding=3, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # é€šé“æ³¨æ„åŠ›
        x_channel = self.channel_att(x) * x
        # ç©ºé—´æ³¨æ„åŠ›
        x_spatial = torch.cat([torch.mean(x_channel, dim=1, keepdim=True),
                               torch.max(x_channel, dim=1, keepdim=True)[0]], dim=1)
        x_spatial = self.spatial_att(x_spatial) * x_channel
        return x_spatial


# EfficientNet-B4 + CBAMæ¨¡å‹
class EfficientNetB4_CBAM_Optimized(nn.Module):
    def __init__(self, num_classes=101):
        super(EfficientNetB4_CBAM_Optimized, self).__init__()
        # ä½¿ç”¨EfficientNet-B4
        try:
            # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„torchvision
            self.backbone = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)
        except:
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æ—§ç‰ˆæœ¬
            self.backbone = models.efficientnet_b4(pretrained=True)
        
        # EfficientNet-B4æœ€åç‰¹å¾é€šé“æ•°æ˜¯1792
        self.cbam = CBAM(1792)
        
        # æ”¹è¿›çš„åˆ†ç±»å¤´
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(1792, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        x = self.backbone.features(x)
        x = self.cbam(x)
        x = self.backbone.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.backbone.classifier(x)
        return x


# æ—©åœç±»
class EarlyStopping:
    def __init__(self, patience=15, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = None
        self.counter = 0
        self.best_weights = None

    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.save_checkpoint(model)
        elif val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            self.save_checkpoint(model)
        else:
            self.counter += 1

        if self.counter >= self.patience:
            if self.restore_best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False

    def save_checkpoint(self, model):
        self.best_weights = model.state_dict().copy()


# ä¼˜åŒ–çš„è®­ç»ƒå‡½æ•°
def train_model_optimized(model, train_loader, val_loader, device, epochs, optimizer, loss_fn, save_path):
    """ä¼˜åŒ–çš„è®­ç»ƒæ¨¡å‹"""
    model.to(device)
    best_acc = 0
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    use_amp = device.type == 'cuda'
    scaler = GradScaler() if use_amp else None
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨OneCycleLR
    scheduler = OneCycleLR(optimizer, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_loader))
    
    # æ—©åœ
    early_stopping = EarlyStopping(patience=20, min_delta=0.001)
    
    print(f"\nå¼€å§‹è®­ç»ƒ {epochs} ä¸ªepoch...")
    print("=" * 60)
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss, train_acc = 0, 0
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè®­ç»ƒè¿›åº¦
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} - è®­ç»ƒ", 
                         leave=False, ncols=100, colour='green')
        
        for batch_idx, (images, labels) in enumerate(train_pbar):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            
            if use_amp:
                with autocast():
                    outputs = model(images)
                    loss = loss_fn(outputs, labels)
                scaler.scale(loss).backward()
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(images)
                loss = loss_fn(outputs, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            train_loss += loss.item()
            train_acc += (outputs.argmax(1) == labels).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = optimizer.param_groups[0]['lr']
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{(outputs.argmax(1) == labels).float().mean():.4f}',
                'LR': f'{current_lr:.6f}'
            })
        
        train_loss /= len(train_loader)
        train_acc /= len(train_loader.dataset)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss, val_acc = 0, 0
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} - éªŒè¯", 
                          leave=False, ncols=100, colour='blue')
            
            for images, labels in val_pbar:
                images, labels = images.to(device), labels.to(device)
                
                if use_amp:
                    with autocast():
                        outputs = model(images)
                        loss = loss_fn(outputs, labels)
                else:
                    outputs = model(images)
                    loss = loss_fn(outputs, labels)
                
                val_loss += loss.item()
                val_acc += (outputs.argmax(1) == labels).sum().item()
                
                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{(outputs.argmax(1) == labels).float().mean():.4f}'
                })
        
        val_loss /= len(val_loader)
        val_acc /= len(val_loader.dataset)
        
        # è®°å½•å†å²
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)
        
        # æ—©åœæ£€æŸ¥
        if early_stopping(val_loss, model):
            print(f"\næ—©åœåœ¨ç¬¬ {epoch+1} è½®")
            break
        
        if val_acc > best_acc:
            torch.save(model.state_dict(), save_path)
            best_acc = val_acc
            print(f"\nğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}")
        
        # æ‰“å°epochç»“æœ
        print(f"\nEpoch [{epoch+1}/{epochs}] ç»“æœ:")
        print(f"  è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.4f}")
        print(f"  éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.4f}")
        print(f"  æœ€ä½³: {best_acc:.4f}, å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")
        print("-" * 60)
        
        # GPUå†…å­˜æ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    return train_losses, train_accuracies, val_losses, val_accuracies


# è¯„ä¼°å‡½æ•°
def evaluate_model(model, val_loader, device, loss_fn, use_amp=False):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc="è¯„ä¼°æ¨¡å‹", ncols=100, colour='cyan'):
            images, labels = images.to(device), labels.to(device)
            
            if use_amp:
                with autocast():
                    outputs = model(images)
                    loss = loss_fn(outputs, labels)
            else:
                outputs = model(images)
                loss = loss_fn(outputs, labels)
            
            total_loss += loss.item()
            pred = outputs.argmax(1)
            correct += (pred == labels).sum().item()
            total += labels.size(0)
    
    avg_loss = total_loss / len(val_loader)
    accuracy = correct / total
    
    return avg_loss, accuracy


# è®¡ç®—è¯¦ç»†æŒ‡æ ‡
def calculate_metrics(model, test_loader, device, class_names):
    """è®¡ç®—è¯¦ç»†è¯„ä¼°æŒ‡æ ‡"""
    model.eval()
    all_preds = []
    all_targets = []
    use_amp = device.type == 'cuda'
    
    print("è®¡ç®—è¯¦ç»†æŒ‡æ ‡...")
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="è®¡ç®—æŒ‡æ ‡", ncols=100, colour='magenta'):
            images, labels = images.to(device), labels.to(device)
            
            if use_amp:
                with autocast():
                    outputs = model(images)
            else:
                outputs = model(images)
            
            preds = outputs.argmax(1)
            
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(labels.cpu().numpy())
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(all_targets, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='weighted')
    
    # å„ç±»åˆ«æŒ‡æ ‡ï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªç±»åˆ«ï¼‰
    class_metrics = {}
    for i, class_name in enumerate(class_names[:20]):
        class_mask = np.array(all_targets) == i
        if np.sum(class_mask) > 0:
            class_preds = np.array(all_preds)[class_mask]
            class_targets = np.array(all_targets)[class_mask]
            class_acc = accuracy_score(class_targets, class_preds)
            class_precision, class_recall, class_f1, _ = precision_recall_fscore_support(
                class_targets, class_preds, average='weighted', zero_division=0
            )
            class_metrics[class_name] = {
                'accuracy': class_acc,
                'precision': class_precision,
                'recall': class_recall,
                'f1': class_f1
            }
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'class_metrics': class_metrics,
        'predictions': all_preds,
        'targets': all_targets
    }


# ç»˜åˆ¶è®­ç»ƒæ›²çº¿
def plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, save_path):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # æŸå¤±æ›²çº¿
    axes[0].plot(train_losses, label='Training Loss', color='blue', linewidth=2)
    axes[0].plot(val_losses, label='Validation Loss', color='red', linewidth=2)
    axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].legend(fontsize=12)
    axes[0].grid(True, alpha=0.3)
    
    # å‡†ç¡®ç‡æ›²çº¿
    axes[1].plot(train_accuracies, label='Training Accuracy', color='blue', linewidth=2)
    axes[1].plot(val_accuracies, label='Validation Accuracy', color='red', linewidth=2)
    axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy', fontsize=12)
    axes[1].legend(fontsize=12)
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


# ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªç±»åˆ«ï¼‰
def plot_confusion_matrix(y_true, y_pred, class_names, save_path):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    # åªæ˜¾ç¤ºå‰20ä¸ªç±»åˆ«
    mask = np.array(y_true) < 20
    y_true_subset = np.array(y_true)[mask]
    y_pred_subset = np.array(y_pred)[mask]
    class_names_subset = class_names[:20]
    
    cm = confusion_matrix(y_true_subset, y_pred_subset)
    
    plt.figure(figsize=(15, 12))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=class_names_subset,
               yticklabels=class_names_subset)
    plt.title('Confusion Matrix (Top 20 Classes)', fontsize=16, fontweight='bold')
    plt.xlabel('Predicted Class', fontsize=12)
    plt.ylabel('True Class', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


# ç»˜åˆ¶å„ç±»åˆ«æ€§èƒ½
def plot_class_performance(class_metrics, save_path):
    """ç»˜åˆ¶å„ç±»åˆ«æ€§èƒ½"""
    classes = list(class_metrics.keys())
    precision = [class_metrics[cls]['precision'] for cls in classes]
    recall = [class_metrics[cls]['recall'] for cls in classes]
    f1 = [class_metrics[cls]['f1'] for cls in classes]
    
    x = np.arange(len(classes))
    width = 0.25
    
    fig, ax = plt.subplots(figsize=(20, 8))
    ax.bar(x - width, precision, width, label='Precision', alpha=0.8, color='skyblue')
    ax.bar(x, recall, width, label='Recall', alpha=0.8, color='lightcoral')
    ax.bar(x + width, f1, width, label='F1-Score', alpha=0.8, color='lightgreen')
    
    ax.set_xlabel('Class', fontsize=12, fontweight='bold')
    ax.set_ylabel('Score', fontsize=12, fontweight='bold')
    ax.set_title('Performance Metrics by Class (Top 20)', fontsize=16, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(classes, rotation=45, ha='right')
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 1.1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (p, r, f) in enumerate(zip(precision, recall, f1)):
        ax.text(i - width, p + 0.01, f'{p:.2f}', ha='center', va='bottom', fontsize=8)
        ax.text(i, r + 0.01, f'{r:.2f}', ha='center', va='bottom', fontsize=8)
        ax.text(i + width, f + 0.01, f'{f:.2f}', ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼˜åŒ–çš„Food-101 EfficientNet-B4 + CBAMè®­ç»ƒ")
    print("ğŸ¯ ç›®æ ‡å‡†ç¡®ç‡: 90%+")
    print("=" * 60)
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path("results_food101_efficientnet_b4_optimized")
    results_dir.mkdir(exist_ok=True)
    
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    data_path = "data/food101/food-101"
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        return
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ“ åŠ è½½æ•°æ®é›†...")
    train_set = Food101Dataset(data_path, "train.txt", "train")
    val_set = Food101Dataset(data_path, "test.txt", "val")
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_set)} æ ·æœ¬")
    print(f"âœ… éªŒè¯é›†: {len(val_set)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    if torch.cuda.is_available():
        batch_size = 12  # é€‚ä¸­çš„æ‰¹é‡å¤§å°
        num_workers = 4
    else:
        batch_size = 6
        num_workers = 0
    
    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)
    
    print(f"ğŸ“Š Batch size: {batch_size}, Num workers: {num_workers}")
    
    # è®¾å¤‡é…ç½®
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"ğŸ”¥ ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        device = torch.device("cpu")
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
    
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ—ï¸  åˆ›å»ºEfficientNet-B4 + CBAMæ¨¡å‹...")
    model = EfficientNetB4_CBAM_Optimized(num_classes=101)
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“ˆ æ¨¡å‹å‚æ•°é‡: {total_params:,}")
    print(f"ğŸ”§ å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
    loss_fn = LabelSmoothingCrossEntropy(smoothing=0.1)
    
    # GPUå†…å­˜ä¼˜åŒ–
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("ğŸ§¹ å·²æ¸…ç†GPUç¼“å­˜")
    
    # è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    train_losses, train_accuracies, val_losses, val_accuracies = train_model_optimized(
        model, train_loader, val_loader, device, 150, optimizer, loss_fn, 
        str(results_dir / "best_model.pth")
    )
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
    print("\nğŸ“¥ åŠ è½½æœ€ä½³æ¨¡å‹...")
    model.load_state_dict(torch.load(results_dir / "best_model.pth"))
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    print("\nğŸ“Š è®¡ç®—è¯¦ç»†æŒ‡æ ‡...")
    metrics = calculate_metrics(model, val_loader, device, train_set.class_names)
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ‰ è®­ç»ƒç»“æœ")
    print("=" * 60)
    print(f"ğŸ¯ æµ‹è¯•å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
    print(f"ğŸ“ˆ æµ‹è¯•ç²¾ç¡®ç‡: {metrics['precision']:.4f}")
    print(f"ğŸ“Š æµ‹è¯•å¬å›ç‡: {metrics['recall']:.4f}")
    print(f"âš–ï¸  æµ‹è¯•F1åˆ†æ•°: {metrics['f1']:.4f}")
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
    if metrics['accuracy'] >= 0.90:
        print("ğŸ‰ æ­å–œï¼å·²è¾¾åˆ°90%+å‡†ç¡®ç‡ç›®æ ‡ï¼")
    else:
        print(f"âš ï¸  å½“å‰å‡†ç¡®ç‡: {metrics['accuracy']:.4f}, ç›®æ ‡: 0.90")
    
    # å„ç±»åˆ«æ€§èƒ½ï¼ˆå‰20ä¸ªç±»åˆ«ï¼‰
    print("\nğŸ“‹ å„ç±»åˆ«æ€§èƒ½ (å‰20ä¸ªç±»åˆ«):")
    for class_name, class_metrics in metrics['class_metrics'].items():
        print(f"  {class_name}: å‡†ç¡®ç‡={class_metrics['accuracy']:.3f}, "
              f"ç²¾ç¡®ç‡={class_metrics['precision']:.3f}, "
              f"å¬å›ç‡={class_metrics['recall']:.3f}, "
              f"F1={class_metrics['f1']:.3f}")
    
    # ä¿å­˜ç»“æœ
    results = {
        'model': 'EfficientNetB4_CBAM_Optimized',
        'dataset': 'Food-101',
        'epochs': 150,
        'test_metrics': {
            'accuracy': metrics['accuracy'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1': metrics['f1']
        },
        'class_metrics': metrics['class_metrics'],
        'timestamp': datetime.now().isoformat()
    }
    
    with open(results_dir / 'results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ç»˜åˆ¶å›¾è¡¨
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies,
                        results_dir / 'training_curves.png')
    plot_confusion_matrix(metrics['targets'], metrics['predictions'], train_set.class_names,
                         results_dir / 'confusion_matrix.png')
    plot_class_performance(metrics['class_metrics'], results_dir / 'class_performance.png')
    
    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")


if __name__ == "__main__":
    main()
